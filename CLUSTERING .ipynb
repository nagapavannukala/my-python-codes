{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Avg_Mthly_Spend</th>\n",
       "      <th>No_Of_Visits</th>\n",
       "      <th>Apparel_Items</th>\n",
       "      <th>FnV_Items</th>\n",
       "      <th>Staples_Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>7000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>7000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>6500</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>6000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>G</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>I</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>J</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cust_ID Name  Avg_Mthly_Spend  No_Of_Visits  Apparel_Items  FnV_Items  \\\n",
       "0        1    A            10000             2              1          1   \n",
       "1        2    B             7000             3              0         10   \n",
       "2        3    C             7000             7              1          3   \n",
       "3        4    D             6500             5              1          1   \n",
       "4        5    E             6000             6              0         12   \n",
       "5        6    F             4000             3              0          1   \n",
       "6        7    G             2500             5              0         11   \n",
       "7        8    H             2500             3              0          1   \n",
       "8        9    I             2000             2              0          2   \n",
       "9       10    J             1000             4              0          1   \n",
       "\n",
       "   Staples_Items  \n",
       "0              0  \n",
       "1              9  \n",
       "2              4  \n",
       "3              4  \n",
       "4              3  \n",
       "5              8  \n",
       "6              2  \n",
       "7              1  \n",
       "8              2  \n",
       "9              7  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RCDF = pd.read_csv(\"Cust_Spend_Data.csv\")\n",
    "RCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pdist in module scipy.spatial.distance:\n",
      "\n",
      "pdist(X, metric='euclidean', p=None, w=None, V=None, VI=None)\n",
      "    Pairwise distances between observations in n-dimensional space.\n",
      "    \n",
      "    See Notes for common calling conventions.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : ndarray\n",
      "        An m by n array of m original observations in an\n",
      "        n-dimensional space.\n",
      "    metric : str or function, optional\n",
      "        The distance metric to use. The distance function can\n",
      "        be 'braycurtis', 'canberra', 'chebyshev', 'cityblock',\n",
      "        'correlation', 'cosine', 'dice', 'euclidean', 'hamming',\n",
      "        'jaccard', 'kulsinski', 'mahalanobis', 'matching',\n",
      "        'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n",
      "        'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'.\n",
      "    p : double, optional\n",
      "        The p-norm to apply\n",
      "        Only for Minkowski, weighted and unweighted. Default: 2.\n",
      "    w : ndarray, optional\n",
      "        The weight vector.\n",
      "        Only for weighted Minkowski. Mandatory\n",
      "    V : ndarray, optional\n",
      "        The variance vector\n",
      "        Only for standardized Euclidean. Default: var(X, axis=0, ddof=1)\n",
      "    VI : ndarray, optional\n",
      "        The inverse of the covariance matrix\n",
      "        Only for Mahalanobis. Default: inv(cov(X.T)).T\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Y : ndarray\n",
      "        Returns a condensed distance matrix Y.  For\n",
      "        each :math:`i` and :math:`j` (where :math:`i<j<m`),where m is the number\n",
      "        of original observations. The metric ``dist(u=X[i], v=X[j])``\n",
      "        is computed and stored in entry ``ij``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    squareform : converts between condensed distance matrices and\n",
      "                 square distance matrices.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See ``squareform`` for information on how to calculate the index of\n",
      "    this entry or to convert the condensed distance matrix to a\n",
      "    redundant square matrix.\n",
      "    \n",
      "    The following are common calling conventions.\n",
      "    \n",
      "    1. ``Y = pdist(X, 'euclidean')``\n",
      "    \n",
      "       Computes the distance between m points using Euclidean distance\n",
      "       (2-norm) as the distance metric between the points. The points\n",
      "       are arranged as m n-dimensional row vectors in the matrix X.\n",
      "    \n",
      "    2. ``Y = pdist(X, 'minkowski', p)``\n",
      "    \n",
      "       Computes the distances using the Minkowski distance\n",
      "       :math:`||u-v||_p` (p-norm) where :math:`p \\geq 1`.\n",
      "    \n",
      "    3. ``Y = pdist(X, 'cityblock')``\n",
      "    \n",
      "       Computes the city block or Manhattan distance between the\n",
      "       points.\n",
      "    \n",
      "    4. ``Y = pdist(X, 'seuclidean', V=None)``\n",
      "    \n",
      "       Computes the standardized Euclidean distance. The standardized\n",
      "       Euclidean distance between two n-vectors ``u`` and ``v`` is\n",
      "    \n",
      "       .. math::\n",
      "    \n",
      "          \\sqrt{\\sum {(u_i-v_i)^2 / V[x_i]}}\n",
      "    \n",
      "    \n",
      "       V is the variance vector; V[i] is the variance computed over all\n",
      "       the i'th components of the points.  If not passed, it is\n",
      "       automatically computed.\n",
      "    \n",
      "    5. ``Y = pdist(X, 'sqeuclidean')``\n",
      "    \n",
      "       Computes the squared Euclidean distance :math:`||u-v||_2^2` between\n",
      "       the vectors.\n",
      "    \n",
      "    6. ``Y = pdist(X, 'cosine')``\n",
      "    \n",
      "       Computes the cosine distance between vectors u and v,\n",
      "    \n",
      "       .. math::\n",
      "    \n",
      "          1 - \\frac{u \\cdot v}\n",
      "                   {{||u||}_2 {||v||}_2}\n",
      "    \n",
      "       where :math:`||*||_2` is the 2-norm of its argument ``*``, and\n",
      "       :math:`u \\cdot v` is the dot product of ``u`` and ``v``.\n",
      "    \n",
      "    7. ``Y = pdist(X, 'correlation')``\n",
      "    \n",
      "       Computes the correlation distance between vectors u and v. This is\n",
      "    \n",
      "       .. math::\n",
      "    \n",
      "          1 - \\frac{(u - \\bar{u}) \\cdot (v - \\bar{v})}\n",
      "                   {{||(u - \\bar{u})||}_2 {||(v - \\bar{v})||}_2}\n",
      "    \n",
      "       where :math:`\\bar{v}` is the mean of the elements of vector v,\n",
      "       and :math:`x \\cdot y` is the dot product of :math:`x` and :math:`y`.\n",
      "    \n",
      "    8. ``Y = pdist(X, 'hamming')``\n",
      "    \n",
      "       Computes the normalized Hamming distance, or the proportion of\n",
      "       those vector elements between two n-vectors ``u`` and ``v``\n",
      "       which disagree. To save memory, the matrix ``X`` can be of type\n",
      "       boolean.\n",
      "    \n",
      "    9. ``Y = pdist(X, 'jaccard')``\n",
      "    \n",
      "       Computes the Jaccard distance between the points. Given two\n",
      "       vectors, ``u`` and ``v``, the Jaccard distance is the\n",
      "       proportion of those elements ``u[i]`` and ``v[i]`` that\n",
      "       disagree.\n",
      "    \n",
      "    10. ``Y = pdist(X, 'chebyshev')``\n",
      "    \n",
      "       Computes the Chebyshev distance between the points. The\n",
      "       Chebyshev distance between two n-vectors ``u`` and ``v`` is the\n",
      "       maximum norm-1 distance between their respective elements. More\n",
      "       precisely, the distance is given by\n",
      "    \n",
      "       .. math::\n",
      "    \n",
      "          d(u,v) = \\max_i {|u_i-v_i|}\n",
      "    \n",
      "    11. ``Y = pdist(X, 'canberra')``\n",
      "    \n",
      "       Computes the Canberra distance between the points. The\n",
      "       Canberra distance between two points ``u`` and ``v`` is\n",
      "    \n",
      "       .. math::\n",
      "    \n",
      "         d(u,v) = \\sum_i \\frac{|u_i-v_i|}\n",
      "                              {|u_i|+|v_i|}\n",
      "    \n",
      "    \n",
      "    12. ``Y = pdist(X, 'braycurtis')``\n",
      "    \n",
      "       Computes the Bray-Curtis distance between the points. The\n",
      "       Bray-Curtis distance between two points ``u`` and ``v`` is\n",
      "    \n",
      "    \n",
      "       .. math::\n",
      "    \n",
      "            d(u,v) = \\frac{\\sum_i {|u_i-v_i|}}\n",
      "                           {\\sum_i {|u_i+v_i|}}\n",
      "    \n",
      "    13. ``Y = pdist(X, 'mahalanobis', VI=None)``\n",
      "    \n",
      "       Computes the Mahalanobis distance between the points. The\n",
      "       Mahalanobis distance between two points ``u`` and ``v`` is\n",
      "       :math:`\\sqrt{(u-v)(1/V)(u-v)^T}` where :math:`(1/V)` (the ``VI``\n",
      "       variable) is the inverse covariance. If ``VI`` is not None,\n",
      "       ``VI`` will be used as the inverse covariance matrix.\n",
      "    \n",
      "    14. ``Y = pdist(X, 'yule')``\n",
      "    \n",
      "       Computes the Yule distance between each pair of boolean\n",
      "       vectors. (see yule function documentation)\n",
      "    \n",
      "    15. ``Y = pdist(X, 'matching')``\n",
      "    \n",
      "       Synonym for 'hamming'.\n",
      "    \n",
      "    16. ``Y = pdist(X, 'dice')``\n",
      "    \n",
      "       Computes the Dice distance between each pair of boolean\n",
      "       vectors. (see dice function documentation)\n",
      "    \n",
      "    17. ``Y = pdist(X, 'kulsinski')``\n",
      "    \n",
      "       Computes the Kulsinski distance between each pair of\n",
      "       boolean vectors. (see kulsinski function documentation)\n",
      "    \n",
      "    18. ``Y = pdist(X, 'rogerstanimoto')``\n",
      "    \n",
      "       Computes the Rogers-Tanimoto distance between each pair of\n",
      "       boolean vectors. (see rogerstanimoto function documentation)\n",
      "    \n",
      "    19. ``Y = pdist(X, 'russellrao')``\n",
      "    \n",
      "       Computes the Russell-Rao distance between each pair of\n",
      "       boolean vectors. (see russellrao function documentation)\n",
      "    \n",
      "    20. ``Y = pdist(X, 'sokalmichener')``\n",
      "    \n",
      "       Computes the Sokal-Michener distance between each pair of\n",
      "       boolean vectors. (see sokalmichener function documentation)\n",
      "    \n",
      "    21. ``Y = pdist(X, 'sokalsneath')``\n",
      "    \n",
      "       Computes the Sokal-Sneath distance between each pair of\n",
      "       boolean vectors. (see sokalsneath function documentation)\n",
      "    \n",
      "    22. ``Y = pdist(X, 'wminkowski')``\n",
      "    \n",
      "       Computes the weighted Minkowski distance between each pair of\n",
      "       vectors. (see wminkowski function documentation)\n",
      "    \n",
      "    23. ``Y = pdist(X, f)``\n",
      "    \n",
      "       Computes the distance between all pairs of vectors in X\n",
      "       using the user supplied 2-arity function f. For example,\n",
      "       Euclidean distance between the vectors could be computed\n",
      "       as follows::\n",
      "    \n",
      "         dm = pdist(X, lambda u, v: np.sqrt(((u-v)**2).sum()))\n",
      "    \n",
      "       Note that you should avoid passing a reference to one of\n",
      "       the distance functions defined in this library. For example,::\n",
      "    \n",
      "         dm = pdist(X, sokalsneath)\n",
      "    \n",
      "       would calculate the pair-wise distances between the vectors in\n",
      "       X using the Python function sokalsneath. This would result in\n",
      "       sokalsneath being called :math:`{n \\choose 2}` times, which\n",
      "       is inefficient. Instead, the optimized C version is more\n",
      "       efficient, and we call it using the following syntax.::\n",
      "    \n",
      "         dm = pdist(X, 'sokalsneath')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagapavan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Distance Computation\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "pdist ## Ctrl + i\n",
    "help(pdist)\n",
    "d_euc = pdist(RCDF.ix[:,2:7], metric  = \"euclidean\") ## index starts from '0',last one is exclusive i.e., 7 is exclusive.\n",
    "\n",
    "type(d_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linkage in module scipy.cluster.hierarchy:\n",
      "\n",
      "linkage(y, method='single', metric='euclidean')\n",
      "    Performs hierarchical/agglomerative clustering.\n",
      "    \n",
      "    The input y may be either a 1d compressed distance matrix\n",
      "    or a 2d array of observation vectors.\n",
      "    \n",
      "    If y is a 1d compressed distance matrix,\n",
      "    then y must be a :math:`{n \\choose 2}` sized\n",
      "    vector where n is the number of original observations paired\n",
      "    in the distance matrix. The behavior of this function is very\n",
      "    similar to the MATLAB linkage function.\n",
      "    \n",
      "    A :math:`(n-1)` by 4 matrix ``Z`` is returned. At the\n",
      "    :math:`i`-th iteration, clusters with indices ``Z[i, 0]`` and\n",
      "    ``Z[i, 1]`` are combined to form cluster :math:`n + i`. A\n",
      "    cluster with an index less than :math:`n` corresponds to one of\n",
      "    the :math:`n` original observations. The distance between\n",
      "    clusters ``Z[i, 0]`` and ``Z[i, 1]`` is given by ``Z[i, 2]``. The\n",
      "    fourth value ``Z[i, 3]`` represents the number of original\n",
      "    observations in the newly formed cluster.\n",
      "    \n",
      "    The following linkage methods are used to compute the distance\n",
      "    :math:`d(s, t)` between two clusters :math:`s` and\n",
      "    :math:`t`. The algorithm begins with a forest of clusters that\n",
      "    have yet to be used in the hierarchy being formed. When two\n",
      "    clusters :math:`s` and :math:`t` from this forest are combined\n",
      "    into a single cluster :math:`u`, :math:`s` and :math:`t` are\n",
      "    removed from the forest, and :math:`u` is added to the\n",
      "    forest. When only one cluster remains in the forest, the algorithm\n",
      "    stops, and this cluster becomes the root.\n",
      "    \n",
      "    A distance matrix is maintained at each iteration. The ``d[i,j]``\n",
      "    entry corresponds to the distance between cluster :math:`i` and\n",
      "    :math:`j` in the original forest.\n",
      "    \n",
      "    At each iteration, the algorithm must update the distance matrix\n",
      "    to reflect the distance of the newly formed cluster u with the\n",
      "    remaining clusters in the forest.\n",
      "    \n",
      "    Suppose there are :math:`|u|` original observations\n",
      "    :math:`u[0], \\ldots, u[|u|-1]` in cluster :math:`u` and\n",
      "    :math:`|v|` original objects :math:`v[0], \\ldots, v[|v|-1]` in\n",
      "    cluster :math:`v`. Recall :math:`s` and :math:`t` are\n",
      "    combined to form cluster :math:`u`. Let :math:`v` be any\n",
      "    remaining cluster in the forest that is not :math:`u`.\n",
      "    \n",
      "    The following are methods for calculating the distance between the\n",
      "    newly formed cluster :math:`u` and each :math:`v`.\n",
      "    \n",
      "      * method='single' assigns\n",
      "    \n",
      "        .. math::\n",
      "           d(u,v) = \\min(dist(u[i],v[j]))\n",
      "    \n",
      "        for all points :math:`i` in cluster :math:`u` and\n",
      "        :math:`j` in cluster :math:`v`. This is also known as the\n",
      "        Nearest Point Algorithm.\n",
      "    \n",
      "      * method='complete' assigns\n",
      "    \n",
      "        .. math::\n",
      "           d(u, v) = \\max(dist(u[i],v[j]))\n",
      "    \n",
      "        for all points :math:`i` in cluster u and :math:`j` in\n",
      "        cluster :math:`v`. This is also known by the Farthest Point\n",
      "        Algorithm or Voor Hees Algorithm.\n",
      "    \n",
      "      * method='average' assigns\n",
      "    \n",
      "        .. math::\n",
      "           d(u,v) = \\sum_{ij} \\frac{d(u[i], v[j])}\n",
      "                                   {(|u|*|v|)}\n",
      "    \n",
      "        for all points :math:`i` and :math:`j` where :math:`|u|`\n",
      "        and :math:`|v|` are the cardinalities of clusters :math:`u`\n",
      "        and :math:`v`, respectively. This is also called the UPGMA\n",
      "        algorithm.\n",
      "    \n",
      "      * method='weighted' assigns\n",
      "    \n",
      "        .. math::\n",
      "           d(u,v) = (dist(s,v) + dist(t,v))/2\n",
      "    \n",
      "        where cluster u was formed with cluster s and t and v\n",
      "        is a remaining cluster in the forest. (also called WPGMA)\n",
      "    \n",
      "      * method='centroid' assigns\n",
      "    \n",
      "        .. math::\n",
      "           dist(s,t) = ||c_s-c_t||_2\n",
      "    \n",
      "        where :math:`c_s` and :math:`c_t` are the centroids of\n",
      "        clusters :math:`s` and :math:`t`, respectively. When two\n",
      "        clusters :math:`s` and :math:`t` are combined into a new\n",
      "        cluster :math:`u`, the new centroid is computed over all the\n",
      "        original objects in clusters :math:`s` and :math:`t`. The\n",
      "        distance then becomes the Euclidean distance between the\n",
      "        centroid of :math:`u` and the centroid of a remaining cluster\n",
      "        :math:`v` in the forest. This is also known as the UPGMC\n",
      "        algorithm.\n",
      "    \n",
      "      * method='median' assigns :math:`d(s,t)` like the ``centroid``\n",
      "        method. When two clusters :math:`s` and :math:`t` are combined\n",
      "        into a new cluster :math:`u`, the average of centroids s and t\n",
      "        give the new centroid :math:`u`. This is also known as the\n",
      "        WPGMC algorithm.\n",
      "    \n",
      "      * method='ward' uses the Ward variance minimization algorithm.\n",
      "        The new entry :math:`d(u,v)` is computed as follows,\n",
      "    \n",
      "        .. math::\n",
      "    \n",
      "           d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
      "                               {T}d(v,s)^2\n",
      "                        + \\frac{|v|+|t|}\n",
      "                               {T}d(v,t)^2\n",
      "                        - \\frac{|v|}\n",
      "                               {T}d(s,t)^2}\n",
      "    \n",
      "        where :math:`u` is the newly joined cluster consisting of\n",
      "        clusters :math:`s` and :math:`t`, :math:`v` is an unused\n",
      "        cluster in the forest, :math:`T=|v|+|s|+|t|`, and\n",
      "        :math:`|*|` is the cardinality of its argument. This is also\n",
      "        known as the incremental algorithm.\n",
      "    \n",
      "    Warning: When the minimum distance pair in the forest is chosen, there\n",
      "    may be two or more pairs with the same minimum distance. This\n",
      "    implementation may chose a different minimum than the MATLAB\n",
      "    version.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y : ndarray\n",
      "        A condensed distance matrix. A condensed distance matrix\n",
      "        is a flat array containing the upper triangular of the distance matrix.\n",
      "        This is the form that ``pdist`` returns. Alternatively, a collection of\n",
      "        :math:`m` observation vectors in :math:`n` dimensions may be passed as an\n",
      "        :math:`m` by :math:`n` array. All elements of the condensed distance matrix\n",
      "        must be finite, i.e. no NaNs or infs.\n",
      "    method : str, optional\n",
      "        The linkage algorithm to use. See the ``Linkage Methods`` section below\n",
      "        for full descriptions.\n",
      "    metric : str or function, optional\n",
      "        The distance metric to use in the case that y is a collection of\n",
      "        observation vectors; ignored otherwise. See the ``pdist``\n",
      "        function for a list of valid distance metrics. A custom distance\n",
      "        function can also be used.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Z : ndarray\n",
      "        The hierarchical clustering encoded as a linkage matrix.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    1. For method 'single' an optimized algorithm based on minimum spanning\n",
      "       tree is implemented. It has time complexity :math:`O(n^2)`.\n",
      "       For methods 'complete', 'average', 'weighted' and 'ward' an algorithm\n",
      "       called nearest-neighbors chain is implemented. It also has time\n",
      "       complexity :math:`O(n^2)`.\n",
      "       For other methods a naive algorithm is implemented with :math:`O(n^3)`\n",
      "       time complexity.\n",
      "       All algorithms use :math:`O(n^2)` memory.\n",
      "       Refer to [1]_ for details about the algorithms.\n",
      "    2. Methods 'centroid', 'median' and 'ward' are correctly defined only if\n",
      "       Euclidean pairwise metric is used. If `y` is passed as precomputed\n",
      "       pairwise distances, then it is a user responsibility to assure that\n",
      "       these distances are in fact Euclidean, otherwise the produced result\n",
      "       will be incorrect.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.spatial.distance.pdist : pairwise distance metrics\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Daniel Mullner, \"Modern hierarchical, agglomerative clustering\n",
      "           algorithms\", :arXiv:`1109.2378v1`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the Clusters\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cut_tree\n",
    "\n",
    "help(linkage)\n",
    "clus1 = linkage(d_euc, method = \"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Displaying the Clusters in Dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "dendrogram(clus1, labels=RCDF.ix[:,[1]].values.tolist())\n",
    "plt.xlabel('hclust')\n",
    "plt.ylabel('Distance')\n",
    "plt.suptitle('Cluster Dendrogram', fontweight='bold', fontsize=14);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.88649751, -1.24034735,  1.52752523, -0.74143264, -1.38013112],\n",
       "       [ 0.78756692, -0.62017367, -0.65465367,  1.28065638,  1.7251639 ],\n",
       "       [ 0.78756692,  1.86052102,  1.52752523, -0.29207953,  0.        ],\n",
       "       [ 0.60441182,  0.62017367,  1.52752523, -0.74143264,  0.        ],\n",
       "       [ 0.42125673,  1.24034735, -0.65465367,  1.7300095 , -0.34503278],\n",
       "       [-0.31136367, -0.62017367, -0.65465367, -0.74143264,  1.38013112],\n",
       "       [-0.86082896,  0.62017367, -0.65465367,  1.50533294, -0.69006556],\n",
       "       [-0.86082896, -0.62017367, -0.65465367, -0.74143264, -1.03509834],\n",
       "       [-1.04398406, -1.24034735, -0.65465367, -0.51675608, -0.69006556],\n",
       "       [-1.41029426,  0.        , -0.65465367, -0.74143264,  1.03509834]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hierarchical Clustering with Scaling\n",
    "from sklearn.preprocessing import scale as scale\n",
    "## scale function standardizes the values\n",
    "## Note - The scale function calculates the \n",
    "## Std. Dev assuming data is Sample\n",
    "scaled_RCDF = scale(RCDF.ix[:,2:7])\n",
    "scaled_RCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Mthly_Spend</th>\n",
       "      <th>No_Of_Visits</th>\n",
       "      <th>Apparel_Items</th>\n",
       "      <th>FnV_Items</th>\n",
       "      <th>Staples_Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.789689</td>\n",
       "      <td>-1.176697</td>\n",
       "      <td>1.449138</td>\n",
       "      <td>-0.703385</td>\n",
       "      <td>-1.309307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.747152</td>\n",
       "      <td>-0.588348</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>1.214937</td>\n",
       "      <td>1.636634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747152</td>\n",
       "      <td>1.765045</td>\n",
       "      <td>1.449138</td>\n",
       "      <td>-0.277091</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.573395</td>\n",
       "      <td>0.588348</td>\n",
       "      <td>1.449138</td>\n",
       "      <td>-0.703385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.399639</td>\n",
       "      <td>1.176697</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>1.641231</td>\n",
       "      <td>-0.327327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.295386</td>\n",
       "      <td>-0.588348</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.703385</td>\n",
       "      <td>1.309307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.816654</td>\n",
       "      <td>0.588348</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>1.428084</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.816654</td>\n",
       "      <td>-0.588348</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.703385</td>\n",
       "      <td>-0.981981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.990410</td>\n",
       "      <td>-1.176697</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.490238</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.337923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.703385</td>\n",
       "      <td>0.981981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_Mthly_Spend  No_Of_Visits  Apparel_Items  FnV_Items  Staples_Items\n",
       "0         1.789689     -1.176697       1.449138  -0.703385      -1.309307\n",
       "1         0.747152     -0.588348      -0.621059   1.214937       1.636634\n",
       "2         0.747152      1.765045       1.449138  -0.277091       0.000000\n",
       "3         0.573395      0.588348       1.449138  -0.703385       0.000000\n",
       "4         0.399639      1.176697      -0.621059   1.641231      -0.327327\n",
       "5        -0.295386     -0.588348      -0.621059  -0.703385       1.309307\n",
       "6        -0.816654      0.588348      -0.621059   1.428084      -0.654654\n",
       "7        -0.816654     -0.588348      -0.621059  -0.703385      -0.981981\n",
       "8        -0.990410     -1.176697      -0.621059  -0.490238      -0.654654\n",
       "9        -1.337923      0.000000      -0.621059  -0.703385       0.981981"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note - Here we are scaling taking \n",
    "## the data as Population\n",
    "scaled_RCDF = RCDF.ix[:,2:7].apply(\n",
    "        lambda x: (x- x.mean())/x.std())\n",
    "scaled_RCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_RCDF = scale(RCDF.ix[:,2:7])\n",
    "d_euc = pdist(scaled_RCDF, \n",
    "              metric  = \"euclidean\")\n",
    "clus2 = linkage(d_euc, method = \"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEmCAYAAACNq4wIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5f4/1hfpjWBeb68AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c3d1fd37b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dendrogram(clus2, \n",
    "           labels=RCDF.ix[:,[1]].values.tolist())\n",
    "plt.xlabel('hclust')\n",
    "plt.ylabel('Distance')\n",
    "plt.suptitle('Cluster Dendrogram', \n",
    "             fontweight='bold', fontsize=14)\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.     4.482  3.596  2.648  4.499  4.195  4.615  3.58   3.725  4.796]\n",
      " [ 4.482  0.     4.045  3.66   2.843  2.327  3.184  3.798  3.578  3.127]\n",
      " [ 3.596  4.045  0.     1.332  3.08   3.772  3.567  3.861  4.273  3.785]\n",
      " [ 2.648  3.66   1.332  0.     3.377  3.007  3.526  3.085  3.386  3.206]\n",
      " [ 4.499  2.843  3.08   3.377  0.     3.617  1.483  3.419  3.67   3.592]\n",
      " [ 4.195  2.327  3.772  3.007  3.617  0.     3.343  2.477  2.293  1.308]\n",
      " [ 4.615  3.184  3.567  3.526  1.483  3.343  0.     2.589  2.754  2.951]\n",
      " [ 3.58   3.798  3.861  3.085  3.419  2.477  2.589  0.     0.767  2.23 ]\n",
      " [ 3.725  3.578  4.273  3.386  3.67   2.293  2.754  0.767  0.     2.168]\n",
      " [ 4.796  3.127  3.785  3.206  3.592  1.308  2.951  2.23   2.168  0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.76660834,  1.30817103,  1.33188797,  1.48252699,  2.29187962,\n",
       "        3.01368978,  3.12171991,  3.23053961,  3.78685213])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.round(squareform(d_euc).tolist(),3))\n",
    "\n",
    "distance = clus2[:,2]\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clusters</th>\n",
       "      <th>Avg_Mthly_Spend</th>\n",
       "      <th>No_Of_Visits</th>\n",
       "      <th>Apparel_Items</th>\n",
       "      <th>FnV_Items</th>\n",
       "      <th>Staples_Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7833.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5166.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2375.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clusters  Avg_Mthly_Spend  No_Of_Visits  Apparel_Items  FnV_Items  \\\n",
       "0         0      7833.333333      4.666667            1.0   1.666667   \n",
       "1         1      5166.666667      4.666667            0.0  11.000000   \n",
       "2         2      2375.000000      3.000000            0.0   1.250000   \n",
       "\n",
       "   Staples_Items  \n",
       "0       2.666667  \n",
       "1       4.666667  \n",
       "2       4.500000  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Profiling Step\n",
    "RCDF['Clusters'] = cut_tree(clus2, 3)\n",
    "clus_profile = RCDF.ix[:,2:8].groupby(['Clusters'], as_index=False).mean()\n",
    "clus_profile \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Avg_Mthly_Spend</th>\n",
       "      <th>No_Of_Visits</th>\n",
       "      <th>Apparel_Items</th>\n",
       "      <th>FnV_Items</th>\n",
       "      <th>Staples_Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>7000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>7000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>6500</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>6000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>G</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "      <td>2500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>I</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>J</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cust_ID Name  Avg_Mthly_Spend  No_Of_Visits  Apparel_Items  FnV_Items  \\\n",
       "0        1    A            10000             2              1          1   \n",
       "1        2    B             7000             3              0         10   \n",
       "2        3    C             7000             7              1          3   \n",
       "3        4    D             6500             5              1          1   \n",
       "4        5    E             6000             6              0         12   \n",
       "5        6    F             4000             3              0          1   \n",
       "6        7    G             2500             5              0         11   \n",
       "7        8    H             2500             3              0          1   \n",
       "8        9    I             2000             2              0          2   \n",
       "9       10    J             1000             4              0          1   \n",
       "\n",
       "   Staples_Items  \n",
       "0              0  \n",
       "1              9  \n",
       "2              4  \n",
       "3              4  \n",
       "4              3  \n",
       "5              8  \n",
       "6              2  \n",
       "7              1  \n",
       "8              2  \n",
       "9              7  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRCDF = pd.read_csv(\"Cust_Spend_Data.csv\")\n",
    "KRCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagapavan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale as scale\n",
    "scaled_RCDF = scale(KRCDF.ix[:,2:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Identifying the optimal number of clusters \n",
    "# elbow method\n",
    "cluster_range = range( 1, 6 )\n",
    "cluster_wss = []\n",
    "type(cluster_wss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "for num_clusters in cluster_range:\n",
    "  clusters = KMeans( num_clusters )\n",
    "  clusters.fit(scaled_RCDF)\n",
    "  cluster_wss.append( clusters.inertia_ ) \n",
    "  ## append means to assign the value.The cluster function gives \n",
    "  ## results of which inertia is nothing but wss.So we are assigning it to wss so that user can understand.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>cluster_wss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31.741877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19.885638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.534707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.826742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_clusters  cluster_wss\n",
       "0             1    50.000000\n",
       "1             2    31.741877\n",
       "2             3    19.885638\n",
       "3             4    13.534707\n",
       "4             5     7.826742"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "clusters_df = pd.DataFrame( OrderedDict ( \n",
    "        {\"num_clusters\": cluster_range, \n",
    "        \"cluster_wss\": cluster_wss }\n",
    "        ) )\n",
    "clusters_df[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAF3CAYAAACopUwjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c3d20d64a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.xlabel('# Clusters')\n",
    "plt.ylabel('WSS')\n",
    "plt.xticks(np.arange(min(clusters_df.num_clusters), \n",
    "                     max(clusters_df.num_clusters)+1, \n",
    "                     1.0))\n",
    "plt.plot( clusters_df.num_clusters, \n",
    "         clusters_df.cluster_wss, \n",
    "         marker = \"o\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeans in module sklearn.cluster.k_means_:\n",
      "\n",
      "class KMeans(sklearn.base.BaseEstimator, sklearn.base.ClusterMixin, sklearn.base.TransformerMixin)\n",
      " |  K-Means clustering\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <k_means>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  n_clusters : int, optional, default: 8\n",
      " |      The number of clusters to form as well as the number of\n",
      " |      centroids to generate.\n",
      " |  \n",
      " |  init : {'k-means++', 'random' or an ndarray}\n",
      " |      Method for initialization, defaults to 'k-means++':\n",
      " |  \n",
      " |      'k-means++' : selects initial cluster centers for k-mean\n",
      " |      clustering in a smart way to speed up convergence. See section\n",
      " |      Notes in k_init for more details.\n",
      " |  \n",
      " |      'random': choose k observations (rows) at random from data for\n",
      " |      the initial centroids.\n",
      " |  \n",
      " |      If an ndarray is passed, it should be of shape (n_clusters, n_features)\n",
      " |      and gives the initial centers.\n",
      " |  \n",
      " |  n_init : int, default: 10\n",
      " |      Number of time the k-means algorithm will be run with different\n",
      " |      centroid seeds. The final results will be the best output of\n",
      " |      n_init consecutive runs in terms of inertia.\n",
      " |  \n",
      " |  max_iter : int, default: 300\n",
      " |      Maximum number of iterations of the k-means algorithm for a\n",
      " |      single run.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Relative tolerance with regards to inertia to declare convergence\n",
      " |  \n",
      " |  precompute_distances : {'auto', True, False}\n",
      " |      Precompute distances (faster but takes more memory).\n",
      " |  \n",
      " |      'auto' : do not precompute distances if n_samples * n_clusters > 12\n",
      " |      million. This corresponds to about 100MB overhead per job using\n",
      " |      double precision.\n",
      " |  \n",
      " |      True : always precompute distances\n",
      " |  \n",
      " |      False : never precompute distances\n",
      " |  \n",
      " |  verbose : int, default 0\n",
      " |      Verbosity mode.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  copy_x : boolean, default True\n",
      " |      When pre-computing distances it is more numerically accurate to center\n",
      " |      the data first.  If copy_x is True, then the original data is not\n",
      " |      modified.  If False, the original data is modified, and put back before\n",
      " |      the function returns, but small numerical differences may be introduced\n",
      " |      by subtracting and then adding the data mean.\n",
      " |  \n",
      " |  n_jobs : int\n",
      " |      The number of jobs to use for the computation. This works by computing\n",
      " |      each of the n_init runs in parallel.\n",
      " |  \n",
      " |      If -1 all CPUs are used. If 1 is given, no parallel computing code is\n",
      " |      used at all, which is useful for debugging. For n_jobs below -1,\n",
      " |      (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one\n",
      " |      are used.\n",
      " |  \n",
      " |  algorithm : \"auto\", \"full\" or \"elkan\", default=\"auto\"\n",
      " |      K-means algorithm to use. The classical EM-style algorithm is \"full\".\n",
      " |      The \"elkan\" variation is more efficient by using the triangle\n",
      " |      inequality, but currently doesn't support sparse data. \"auto\" chooses\n",
      " |      \"elkan\" for dense data and \"full\" for sparse data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cluster_centers_ : array, [n_clusters, n_features]\n",
      " |      Coordinates of cluster centers\n",
      " |  \n",
      " |  labels_ :\n",
      " |      Labels of each point\n",
      " |  \n",
      " |  inertia_ : float\n",
      " |      Sum of squared distances of samples to their closest cluster center.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> from sklearn.cluster import KMeans\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
      " |  ...               [4, 2], [4, 4], [4, 0]])\n",
      " |  >>> kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
      " |  >>> kmeans.labels_\n",
      " |  array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
      " |  >>> kmeans.predict([[0, 0], [4, 4]])\n",
      " |  array([0, 1], dtype=int32)\n",
      " |  >>> kmeans.cluster_centers_\n",
      " |  array([[ 1.,  2.],\n",
      " |         [ 4.,  2.]])\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  \n",
      " |  MiniBatchKMeans\n",
      " |      Alternative online implementation that does incremental updates\n",
      " |      of the centers positions using mini-batches.\n",
      " |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n",
      " |      probably much faster than the default batch implementation.\n",
      " |  \n",
      " |  Notes\n",
      " |  ------\n",
      " |  The k-means problem is solved using Lloyd's algorithm.\n",
      " |  \n",
      " |  The average complexity is given by O(k n T), were n is the number of\n",
      " |  samples and T is the number of iteration.\n",
      " |  \n",
      " |  The worst case complexity is given by O(n^(k+2/p)) with\n",
      " |  n = n_samples, p = n_features. (D. Arthur and S. Vassilvitskii,\n",
      " |  'How slow is the k-means method?' SoCG2006)\n",
      " |  \n",
      " |  In practice, the k-means algorithm is very fast (one of the fastest\n",
      " |  clustering algorithms available), but it falls in local minima. That's why\n",
      " |  it can be useful to restart it several times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KMeans\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute k-means clustering.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
      " |          Training instances to cluster.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |  \n",
      " |  fit_predict(self, X, y=None)\n",
      " |      Compute cluster centers and predict cluster index for each sample.\n",
      " |      \n",
      " |      Convenience method; equivalent to calling fit(X) followed by\n",
      " |      predict(X).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      u : Ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape [n_samples,]\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Compute clustering and transform X to cluster-distance space.\n",
      " |      \n",
      " |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape [n_samples, k]\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the closest cluster each sample in X belongs to.\n",
      " |      \n",
      " |      In the vector quantization literature, `cluster_centers_` is called\n",
      " |      the code book and each value returned by `predict` is the index of\n",
      " |      the closest code in the code book.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to predict.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape [n_samples,]\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Opposite of the value of X on the K-means objective.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Opposite of the value of X on the K-means objective.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform X to a cluster-distance space.\n",
      " |      \n",
      " |      In the new space, each dimension is the distance to the cluster\n",
      " |      centers.  Note that even if X is sparse, the array returned by\n",
      " |      `transform` will typically be dense.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape [n_samples, k]\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clusters</th>\n",
       "      <th>Avg_Mthly_Spend</th>\n",
       "      <th>No_Of_Visits</th>\n",
       "      <th>Apparel_Items</th>\n",
       "      <th>FnV_Items</th>\n",
       "      <th>Staples_Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2375.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7833.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5166.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clusters  Avg_Mthly_Spend  No_Of_Visits  Apparel_Items  FnV_Items  \\\n",
       "0         0      2375.000000      3.000000            0.0   1.250000   \n",
       "1         1      7833.333333      4.666667            1.0   1.666667   \n",
       "2         2      5166.666667      4.666667            0.0  11.000000   \n",
       "\n",
       "   Staples_Items  \n",
       "0       4.500000  \n",
       "1       2.666667  \n",
       "2       4.666667  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## profiling the clusters\n",
    "help(KMeans)\n",
    "clusterer = KMeans(n_clusters=3, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(scaled_RCDF)\n",
    "cluster_labels\n",
    "KRCDF['Clusters'] = cluster_labels\n",
    "\n",
    "clus_profile = KRCDF.ix[:,2:8].groupby(['Clusters'], \n",
    "                       as_index=False).mean()\n",
    "clus_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_2 = PCA(2)\n",
    "plot_columns = pca_2.fit_transform(scaled_RCDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting a Visual Plot \n",
    "## Defining Colours and Labels for the Plot\n",
    "def color_fun (row):\n",
    "   if (row['Clusters'] == 0):\n",
    "      return \"red\"\n",
    "   if (row['Clusters'] == 1):\n",
    "      return \"green\"\n",
    "   if (row['Clusters'] == 2):\n",
    "      return \"blue\"\n",
    "   return 0\n",
    "\n",
    "KRCDF['color'] = KRCDF.apply (lambda row: color_fun(row), axis=1)\n",
    "\n",
    "plot_labels = KRCDF.ix[:,[1]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0c4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c3d34dd940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Show the Cluster Plot\n",
    "plt.scatter(x=plot_columns[:,0], \n",
    "            y=plot_columns[:,1],\n",
    "            c=KRCDF['color'].values.tolist(),\n",
    "            s=50, edgecolors='none')\n",
    "\n",
    "for label, x, y in zip(\n",
    "        plot_labels, plot_columns[:,0], \n",
    "        plot_columns[:,1]) :\n",
    "    plt.annotate(\n",
    "    label,\n",
    "    xy=(x, y), xytext=(10, 2),\n",
    "    textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0')\n",
    "    )\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
